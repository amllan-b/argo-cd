admin-cache:
  affinity: {}
  allocatedMemory: 64
  annotations: {}
  connectionLimit: 16384
  enabled: true
  extraArgs: {}
  extraContainers: []
  initContainers: []
  maxItemMemory: 1
  nodeSelector: {}
  podAnnotations: {}
  podDisruptionBudget:
    maxUnavailable: 1
  podLabels: {}
  podManagementPolicy: Parallel
  port: 11211
  priorityClassName: null
  replicas: 3
  resources: null
  service:
    annotations: {}
    extraPorts: []
    labels: {}
  statefulStrategy:
    type: RollingUpdate
  terminationGracePeriodSeconds: 60
  tolerations: []
  topologySpreadConstraints: {}
admin_api:
  affinity: {}
  annotations: {}
  containerSecurityContext:
    allowPrivilegeEscalation: false
    capabilities:
      drop:
      - ALL
    readOnlyRootFilesystem: true
  enabled: true
  env: []
  extraArgs: {}
  extraContainers: []
  extraEnvFrom: []
  extraVolumeMounts: []
  extraVolumes: []
  image: null
  initContainers: []
  jaegerReporterMaxQueueSize: null
  nodeSelector: {}
  persistence:
    subPath: null
  podAnnotations: {}
  podDisruptionBudget:
    maxUnavailable: 1
  podLabels: {}
  priorityClassName: null
  readinessProbe:
    httpGet:
      path: /ready
      port: http-metrics
    initialDelaySeconds: 45
  replicas: 1
  resources:
    limits:
      memory: 128Mi
    requests:
      cpu: 100m
      memory: 64Mi
  securityContext: {}
  service:
    annotations: {}
    extraPorts: []
    internalTrafficPolicy: Cluster
    labels: {}
    type: ClusterIP
  strategy:
    rollingUpdate:
      maxSurge: 15%
      maxUnavailable: 0
    type: RollingUpdate
  terminationGracePeriodSeconds: 60
  tolerations: []
  topologySpreadConstraints:
    maxSkew: 1
    topologyKey: kubernetes.io/hostname
    whenUnsatisfiable: ScheduleAnyway
alertmanager:
  affinity: {}
  annotations: {}
  containerSecurityContext:
    allowPrivilegeEscalation: false
    capabilities:
      drop:
      - ALL
    readOnlyRootFilesystem: true
  enabled: true
  env: []
  extraArgs: {}
  extraContainers: []
  extraEnvFrom: []
  extraVolumeMounts: []
  extraVolumes: []
  fallbackConfig: |
    receivers:
        - name: default-receiver
    route:
        receiver: default-receiver
  image: null
  initContainers: []
  jaegerReporterMaxQueueSize: null
  nodeSelector: {}
  persistence:
    subPath: null
  persistentVolume:
    accessModes:
    - ReadWriteOnce
    annotations: {}
    enableRetentionPolicy: false
    enabled: false
    name: storage
    size: 1Gi
    subPath: ""
    whenDeleted: Retain
    whenScaled: Retain
  podAnnotations: {}
  podDisruptionBudget:
    maxUnavailable: 1
  podLabels: {}
  priorityClassName: null
  readinessProbe:
    httpGet:
      path: /ready
      port: http-metrics
    initialDelaySeconds: 45
  resources:
    limits:
      memory: 1.4Gi
    requests:
      cpu: 1
      memory: 1Gi
  schedulerName: ""
  securityContext: {}
  service:
    annotations: {}
    extraPorts: []
    internalTrafficPolicy: Cluster
    labels: {}
    type: ClusterIP
  serviceAccount:
    annotations: {}
    create: false
    labels: {}
    name: ""
  statefulSet:
    enabled: false
  statefulStrategy:
    type: RollingUpdate
  strategy:
    rollingUpdate:
      maxSurge: 0
      maxUnavailable: 1
    type: RollingUpdate
  terminationGracePeriodSeconds: 900
  tolerations: []
  topologySpreadConstraints:
    maxSkew: 1
    topologyKey: kubernetes.io/hostname
    whenUnsatisfiable: ScheduleAnyway
  zoneAwareReplication:
    enabled: false
    maxUnavailable: 2
    migration:
      enabled: false
      writePath: false
    topologyKey: null
    zones:
    - extraAffinity: {}
      name: zone-a
      nodeSelector: null
      storageClass: null
    - extraAffinity: {}
      name: zone-b
      nodeSelector: null
      storageClass: null
    - extraAffinity: {}
      name: zone-c
      nodeSelector: null
      storageClass: null
chunks-cache:
  affinity: {}
  allocatedMemory: 8192
  annotations: {}
  connectionLimit: 16384
  enabled: true
  extraArgs: {}
  extraContainers: []
  extraExtendedOptions: ""
  extraVolumeMounts: []
  extraVolumes: []
  initContainers: []
  maxItemMemory: 1
  nodeSelector: {}
  podAnnotations: {}
  podDisruptionBudget:
    maxUnavailable: 1
  podLabels: {}
  podManagementPolicy: Parallel
  port: 11211
  priorityClassName: null
  replicas: 3
  resources: null
  service:
    annotations: {}
    extraPorts: []
    labels: {}
  statefulStrategy:
    type: RollingUpdate
  terminationGracePeriodSeconds: 30
  tolerations: []
  topologySpreadConstraints: {}
  volumeClaimTemplates: []
compactor:
  affinity: {}
  annotations: {}
  containerSecurityContext:
    allowPrivilegeEscalation: false
    capabilities:
      drop:
      - ALL
    readOnlyRootFilesystem: true
  enabled: true
  env: []
  extraArgs: {}
  extraContainers: []
  extraEnvFrom: []
  extraVolumeMounts: []
  extraVolumes: []
  image: null
  initContainers: []
  jaegerReporterMaxQueueSize: null
  nodeSelector: {}
  persistentVolume:
    accessModes:
    - ReadWriteOnce
    annotations: {}
    enableRetentionPolicy: false
    enabled: true
    name: storage
    size: 20Gi
    subPath: ""
    whenDeleted: Retain
    whenScaled: Retain
  podAnnotations: {}
  podDisruptionBudget:
    maxUnavailable: 1
  podLabels: {}
  podManagementPolicy: OrderedReady
  priorityClassName: null
  readinessProbe:
    httpGet:
      path: /ready
      port: http-metrics
    initialDelaySeconds: 60
  replicas: 1
  resources:
    limits:
      memory: 2.1Gi
    requests:
      cpu: 1
      memory: 1.5Gi
  ring:
    replication-factor: 3
  schedulerName: ""
  securityContext: {}
  service:
    annotations: {}
    extraPorts: []
    internalTrafficPolicy: Cluster
    labels: {}
    type: ClusterIP
  strategy:
    type: RollingUpdate
  terminationGracePeriodSeconds: 900
  tolerations: []
  topologySpreadConstraints:
    maxSkew: 1
    topologyKey: kubernetes.io/hostname
    whenUnsatisfiable: ScheduleAnyway
configStorageType: ConfigMap
continuous_test:
  affinity: {}
  annotations: {}
  auth:
    bearerToken: null
    password: null
    tenant: mimir-continuous-test
    type: tenantId
  containerSecurityContext:
    allowPrivilegeEscalation: false
    capabilities:
      drop:
      - ALL
    readOnlyRootFilesystem: true
  enabled: false
  env: []
  extraArgs: {}
  extraContainers: []
  extraEnvFrom: []
  extraVolumeMounts: []
  extraVolumes: []
  image: null
  initContainers: []
  jaegerReporterMaxQueueSize: null
  maxQueryAge: 48h
  nodeSelector: {}
  numSeries: 1000
  priorityClassName: null
  read: null
  replicas: 1
  resources:
    limits:
      memory: 1Gi
    requests:
      cpu: "1"
      memory: 512Mi
  runInterval: 5m
  securityContext: {}
  service:
    annotations: {}
    extraPorts: []
    labels: {}
  strategy:
    rollingUpdate:
      maxSurge: 0
      maxUnavailable: 1
    type: RollingUpdate
  terminationGracePeriodSeconds: 30
  tolerations: []
  write: null
distributor:
  affinity: {}
  annotations: {}
  containerSecurityContext:
    allowPrivilegeEscalation: false
    capabilities:
      drop:
      - ALL
    readOnlyRootFilesystem: true
  enabled: true
  env: []
  extraArgs:
    log.level: debug
  extraContainers: []
  extraEnvFrom: []
  extraVolumeMounts: []
  extraVolumes: []
  image: null
  initContainers: []
  jaegerReporterMaxQueueSize: 1000
  kedaAutoscaling:
    behavior:
      scaleDown:
        policies:
        - periodSeconds: 600
          type: Percent
          value: 10
    enabled: false
    maxReplicaCount: 10
    minReplicaCount: 1
    preserveReplicas: false
    targetCPUUtilizationPercentage: 100
    targetMemoryUtilizationPercentage: 100
  nodeSelector: {}
  persistence:
    subPath: null
  podAnnotations: {}
  podDisruptionBudget:
    maxUnavailable: 1
  podLabels: {}
  priorityClassName: null
  readinessProbe:
    httpGet:
      path: /ready
      port: http-metrics
    initialDelaySeconds: 45
  replicas: 2
  resources:
    limits:
      memory: 5.7Gi
    requests:
      cpu: 2
      memory: 4Gi
  securityContext: {}
  service:
    annotations: {}
    extraPorts: []
    internalTrafficPolicy: Cluster
    labels: {}
    type: ClusterIP
  strategy:
    rollingUpdate:
      maxSurge: 15%
      maxUnavailable: 0
    type: RollingUpdate
  terminationGracePeriodSeconds: 100
  tolerations: []
  topologySpreadConstraints:
    maxSkew: 1
    topologyKey: kubernetes.io/hostname
    whenUnsatisfiable: ScheduleAnyway
enterprise:
  enabled: false
  image:
    repository: grafana/enterprise-metrics
    tag: v2.16.0
  legacyLabels: false
externalConfigSecretName: '{{ include "mimir.resourceName" (dict "ctx" . "component"
  "config") }}'
externalConfigVersion: "0"
extraObjects: []
federation_frontend:
  affinity: {}
  annotations: {}
  containerSecurityContext:
    allowPrivilegeEscalation: false
    capabilities:
      drop:
      - ALL
    readOnlyRootFilesystem: true
  disableOtherComponents: false
  enabled: false
  env: []
  extraArgs: {}
  extraContainers: []
  extraEnvFrom: []
  extraVolumeMounts: []
  extraVolumes: []
  image: null
  initContainers: []
  jaegerReporterMaxQueueSize: null
  nodeSelector: {}
  podAnnotations: {}
  podDisruptionBudget:
    maxUnavailable: 1
  podLabels: {}
  priorityClassName: null
  readinessProbe:
    httpGet:
      path: /ready
      port: http-metrics
    initialDelaySeconds: 45
  replicas: 2
  resources:
    requests:
      cpu: 100m
      memory: 128Mi
  securityContext: {}
  service:
    annotations: {}
    extraPorts: []
    labels: {}
  strategy:
    rollingUpdate:
      maxSurge: 15%
      maxUnavailable: 0
    type: RollingUpdate
  terminationGracePeriodSeconds: 180
  tolerations: []
fullnameOverride: null
gateway:
  affinity: {}
  annotations: {}
  autoscaling:
    enabled: false
    maxReplicas: 3
    minReplicas: 1
    targetCPUUtilizationPercentage: 70
    targetMemoryUtilizationPercentage: 70
  containerSecurityContext:
    allowPrivilegeEscalation: false
    capabilities:
      drop:
      - ALL
    readOnlyRootFilesystem: true
  enabled: true
  enabledNonEnterprise: false
  env: []
  extraArgs: {}
  extraContainers: []
  extraEnvFrom: []
  extraVolumeMounts: []
  extraVolumes: []
  image: null
  ingress:
    annotations: {}
    enabled: false
    hosts:
    - host: '{{ .Release.Name }}.mimir.example.com'
      paths:
      - path: /
    ingressClassName: ""
    nameOverride: ""
    tls:
    - hosts:
      - '{{ .Release.Name }}.mimir.example.com'
      secretName: mimir-tls
  initContainers: []
  jaegerReporterMaxQueueSize: null
  nginx:
    basicAuth:
      enabled: false
      existingSecret: null
      htpasswd: '{{ htpasswd (required "''gateway.nginx.basicAuth.username'' is required"
        .Values.gateway.nginx.basicAuth.username) (required "''gateway.nginx.basicAuth.password''
        is required" .Values.gateway.nginx.basicAuth.password) }}'
      password: null
      username: null
    config:
      accessLogEnabled: true
      clientMaxBodySize: 540M
      enableIPv6: true
      errorLogLevel: error
      file: |
        worker_processes  5;  ## Default: 1
        error_log  /dev/stderr {{ .Values.gateway.nginx.config.errorLogLevel }};
        pid        /tmp/nginx.pid;
        worker_rlimit_nofile 8192;

        events {
          worker_connections  4096;  ## Default: 1024
        }

        http {
          client_body_temp_path /tmp/client_temp;
          proxy_temp_path       /tmp/proxy_temp_path;
          fastcgi_temp_path     /tmp/fastcgi_temp;
          uwsgi_temp_path       /tmp/uwsgi_temp;
          scgi_temp_path        /tmp/scgi_temp;

          default_type application/octet-stream;
          log_format   {{ .Values.gateway.nginx.config.logFormat }}

          {{- if .Values.gateway.nginx.verboseLogging }}
          access_log   /dev/stderr  main;
          {{- else }}

          map $status $loggable {
            ~^[23]  0;
            default 1;
          }
          access_log   {{ .Values.gateway.nginx.config.accessLogEnabled | ternary "/dev/stderr  main  if=$loggable;" "off;" }}
          {{- end }}

          sendfile           on;
          tcp_nopush         on;
          proxy_http_version 1.1;

          {{- if .Values.gateway.nginx.config.resolver }}
          resolver {{ .Values.gateway.nginx.config.resolver }};
          {{- else }}
          resolver {{ .Values.global.dnsService }}.{{ .Values.global.dnsNamespace }}.svc.{{ .Values.global.clusterDomain }};
          {{- end }}

          {{- with .Values.gateway.nginx.config.httpSnippet }}
          {{ . | nindent 2 }}
          {{- end }}

          # Ensure that X-Scope-OrgID is always present, default to the no_auth_tenant for backwards compatibility when multi-tenancy was turned off.
          map $http_x_scope_orgid $ensured_x_scope_orgid {
            default $http_x_scope_orgid;
            "" "{{ include "mimir.noAuthTenant" . }}";
          }

          map $http_x_scope_orgid $has_multiple_orgid_headers {
            default 0;
            "~^.+,.+$" 1;
          }

          proxy_read_timeout 300;
          server {
            listen {{ include "mimir.serverHttpListenPort" . }};
            {{- if .Values.gateway.nginx.config.enableIPv6 }}
            listen [::]:{{ include "mimir.serverHttpListenPort" . }};
            {{- end }}

            {{- if .Values.gateway.nginx.config.clientMaxBodySize }}
            client_max_body_size {{ .Values.gateway.nginx.config.clientMaxBodySize }};
            {{- end }}

            {{- if .Values.gateway.nginx.basicAuth.enabled }}
            auth_basic           "Mimir";
            auth_basic_user_file /etc/nginx/secrets/.htpasswd;
            {{- end }}

            if ($has_multiple_orgid_headers = 1) {
                return 400 'Sending multiple X-Scope-OrgID headers is not allowed. Use a single header with | as separator instead.';
            }

            location = / {
              return 200 'OK';
              auth_basic off;
            }

            location = /ready {
              return 200 'OK';
              auth_basic off;
            }

            proxy_set_header X-Scope-OrgID $ensured_x_scope_orgid;

            # Distributor endpoints
            location /distributor {
              set $distributor {{ template "mimir.fullname" . }}-distributor-headless.{{ .Release.Namespace }}.svc.{{ .Values.global.clusterDomain }};
              proxy_pass      http://$distributor:{{ include "mimir.serverHttpListenPort" . }}$request_uri;
            }
            location = /api/v1/push {
              set $distributor {{ template "mimir.fullname" . }}-distributor-headless.{{ .Release.Namespace }}.svc.{{ .Values.global.clusterDomain }};
              proxy_pass      http://$distributor:{{ include "mimir.serverHttpListenPort" . }}$request_uri;
            }
            location /otlp/v1/metrics {
              set $distributor {{ template "mimir.fullname" . }}-distributor-headless.{{ .Release.Namespace }}.svc.{{ .Values.global.clusterDomain }};
              proxy_pass      http://$distributor:{{ include "mimir.serverHttpListenPort" . }}$request_uri;
            }

            # Alertmanager endpoints
            location {{ template "mimir.alertmanagerHttpPrefix" . }} {
              set $alertmanager {{ template "mimir.fullname" . }}-alertmanager-headless.{{ .Release.Namespace }}.svc.{{ .Values.global.clusterDomain }};
              proxy_pass      http://$alertmanager:{{ include "mimir.serverHttpListenPort" . }}$request_uri;
            }
            location = /multitenant_alertmanager/status {
              set $alertmanager {{ template "mimir.fullname" . }}-alertmanager-headless.{{ .Release.Namespace }}.svc.{{ .Values.global.clusterDomain }};
              proxy_pass      http://$alertmanager:{{ include "mimir.serverHttpListenPort" . }}$request_uri;
            }
            location = /multitenant_alertmanager/configs {
              set $alertmanager {{ template "mimir.fullname" . }}-alertmanager-headless.{{ .Release.Namespace }}.svc.{{ .Values.global.clusterDomain }};
              proxy_pass      http://$alertmanager:{{ include "mimir.serverHttpListenPort" . }}$request_uri;
            }
            location = /api/v1/alerts {
              set $alertmanager {{ template "mimir.fullname" . }}-alertmanager-headless.{{ .Release.Namespace }}.svc.{{ .Values.global.clusterDomain }};
              proxy_pass      http://$alertmanager:{{ include "mimir.serverHttpListenPort" . }}$request_uri;
            }

            # Ruler endpoints
            location {{ template "mimir.prometheusHttpPrefix" . }}/config/v1/rules {
              set $ruler {{ template "mimir.fullname" . }}-ruler.{{ .Release.Namespace }}.svc.{{ .Values.global.clusterDomain }};
              proxy_pass      http://$ruler:{{ include "mimir.serverHttpListenPort" . }}$request_uri;
            }
            location {{ template "mimir.prometheusHttpPrefix" . }}/api/v1/rules {
              set $ruler {{ template "mimir.fullname" . }}-ruler.{{ .Release.Namespace }}.svc.{{ .Values.global.clusterDomain }};
              proxy_pass      http://$ruler:{{ include "mimir.serverHttpListenPort" . }}$request_uri;
            }

            location {{ template "mimir.prometheusHttpPrefix" . }}/api/v1/alerts {
              set $ruler {{ template "mimir.fullname" . }}-ruler.{{ .Release.Namespace }}.svc.{{ .Values.global.clusterDomain }};
              proxy_pass      http://$ruler:{{ include "mimir.serverHttpListenPort" . }}$request_uri;
            }
            location = /ruler/ring {
              set $ruler {{ template "mimir.fullname" . }}-ruler.{{ .Release.Namespace }}.svc.{{ .Values.global.clusterDomain }};
              proxy_pass      http://$ruler:{{ include "mimir.serverHttpListenPort" . }}$request_uri;
            }

            # Rest of {{ template "mimir.prometheusHttpPrefix" . }} goes to the query frontend
            location {{ template "mimir.prometheusHttpPrefix" . }} {
              set $query_frontend {{ template "mimir.fullname" . }}-query-frontend.{{ .Release.Namespace }}.svc.{{ .Values.global.clusterDomain }};
              proxy_pass      http://$query_frontend:{{ include "mimir.serverHttpListenPort" . }}$request_uri;
            }

            # Buildinfo endpoint can go to any component
            location = /api/v1/status/buildinfo {
              set $query_frontend {{ template "mimir.fullname" . }}-query-frontend.{{ .Release.Namespace }}.svc.{{ .Values.global.clusterDomain }};
              proxy_pass      http://$query_frontend:{{ include "mimir.serverHttpListenPort" . }}$request_uri;
            }

            # Compactor endpoint for uploading blocks
            location /api/v1/upload/block/ {
              set $compactor {{ template "mimir.fullname" . }}-compactor.{{ .Release.Namespace }}.svc.{{ .Values.global.clusterDomain }};
              proxy_pass      http://$compactor:{{ include "mimir.serverHttpListenPort" . }}$request_uri;
            }

            {{- with .Values.gateway.nginx.config.serverSnippet }}
            {{ . | nindent 4 }}
            {{- end }}
          }
        }
      httpSnippet: ""
      logFormat: |-
        main '$remote_addr - $remote_user [$time_local]  $status '
                '"$request" $body_bytes_sent "$http_referer" '
                '"$http_user_agent" "$http_x_forwarded_for"';
      resolver: null
      serverSnippet: ""
    image:
      registry: docker.io
      repository: nginxinc/nginx-unprivileged
      tag: 1.27-alpine
    verboseLogging: true
  nodeSelector: {}
  podAnnotations: {}
  podDisruptionBudget:
    maxUnavailable: 1
  podLabels: {}
  priorityClassName: null
  readinessProbe:
    httpGet:
      path: /ready
      port: http-metrics
    initialDelaySeconds: 15
    timeoutSeconds: 1
  replicas: 1
  resources:
    limits:
      memory: 731Mi
    requests:
      cpu: 1
      memory: 512Mi
  route:
    annotations: {}
    enabled: false
    host: '{{ .Release.Name }}.mimir.example.com'
    tls:
      termination: edge
  securityContext: {}
  service:
    annotations: {}
    clusterIP: null
    extraPorts: []
    internalTrafficPolicy: Cluster
    labels: {}
    legacyPort: 8080
    loadBalancerIP: null
    nameOverride: ""
    nodePort: null
    port: 80
    type: ClusterIP
  strategy:
    rollingUpdate:
      maxSurge: 15%
      maxUnavailable: 0
    type: RollingUpdate
  terminationGracePeriodSeconds: 30
  tolerations: []
  topologySpreadConstraints:
    maxSkew: 1
    topologyKey: kubernetes.io/hostname
    whenUnsatisfiable: ScheduleAnyway
global:
  clusterDomain: cluster.local.
  dnsNamespace: kube-system
  dnsService: kube-dns
  extraEnv: []
  extraEnvFrom: []
  extraVolumeMounts: []
  extraVolumes: []
  podAnnotations: {}
  podLabels: {}
gr-aggr-cache:
  affinity: {}
  allocatedMemory: 8192
  annotations: {}
  connectionLimit: 16384
  enabled: true
  extraArgs: {}
  extraContainers: []
  initContainers: []
  maxItemMemory: 1
  nodeSelector: {}
  podAnnotations: {}
  podDisruptionBudget:
    maxUnavailable: 1
  podLabels: {}
  podManagementPolicy: Parallel
  port: 11211
  priorityClassName: null
  replicas: 1
  resources: null
  service:
    annotations: {}
    extraPorts: []
    labels: {}
  statefulStrategy:
    type: RollingUpdate
  terminationGracePeriodSeconds: 60
  tolerations: []
gr-metricname-cache:
  affinity: {}
  allocatedMemory: 8192
  annotations: {}
  connectionLimit: 16384
  enabled: true
  extraArgs: {}
  extraContainers: []
  initContainers: []
  maxItemMemory: 1
  nodeSelector: {}
  podAnnotations: {}
  podDisruptionBudget:
    maxUnavailable: 1
  podLabels: {}
  podManagementPolicy: Parallel
  port: 11211
  priorityClassName: null
  replicas: 1
  resources: null
  service:
    annotations: {}
    extraPorts: []
    labels: {}
  statefulStrategy:
    type: RollingUpdate
  terminationGracePeriodSeconds: 60
  tolerations: []
grafana-agent-operator:
  containerSecurityContext:
    allowPrivilegeEscalation: false
    capabilities:
      drop:
      - ALL
    readOnlyRootFilesystem: true
  podSecurityContext:
    fsGroup: 10001
    runAsGroup: 10001
    runAsNonRoot: true
    runAsUser: 10001
    seccompProfile:
      type: RuntimeDefault
graphite:
  enabled: false
  querier:
    affinity:
      podAntiAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
        - podAffinityTerm:
            labelSelector:
              matchExpressions:
              - key: app.kubernetes.io/component
                operator: In
                values:
                - graphite-querier
            topologyKey: kubernetes.io/hostname
          weight: 100
    annotations: {}
    containerSecurityContext:
      allowPrivilegeEscalation: false
      capabilities:
        drop:
        - ALL
      readOnlyRootFilesystem: true
    env: []
    extraArgs: {}
    extraContainers: []
    extraEnvFrom: []
    extraVolumeMounts: []
    extraVolumes: []
    initContainers: []
    jaegerReporterMaxQueueSize: null
    livenessProbe:
      httpGet:
        path: /ready
        port: http-metrics
      initialDelaySeconds: 45
    nodeSelector: {}
    persistence:
      subPath: null
    podAnnotations: {}
    podDisruptionBudget:
      maxUnavailable: 1
    podLabels: {}
    priorityClassName: null
    readinessProbe:
      httpGet:
        path: /ready
        port: http-metrics
      initialDelaySeconds: 45
    replicas: 2
    resources:
      requests:
        cpu: 100m
        memory: 128Mi
    schemasConfiguration:
      storageAggregations: |-
        [default]
        aggregationMethod = avg
        pattern = .*
        xFilesFactor = 0.1
      storageSchemas: |-
        [default]
        pattern = .*
        intervals = 0:1s
        retentions = 10s:8d,10m:1y
    securityContext: {}
    service:
      annotations: {}
      extraPorts: []
      labels: {}
    strategy:
      rollingUpdate:
        maxSurge: 15%
        maxUnavailable: 0
      type: RollingUpdate
    terminationGracePeriodSeconds: 180
    tolerations: []
  write_proxy:
    affinity:
      podAntiAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
        - podAffinityTerm:
            labelSelector:
              matchExpressions:
              - key: app.kubernetes.io/component
                operator: In
                values:
                - graphite-write-proxy
            topologyKey: kubernetes.io/hostname
          weight: 100
    annotations: {}
    containerSecurityContext:
      allowPrivilegeEscalation: false
      capabilities:
        drop:
        - ALL
      readOnlyRootFilesystem: true
    env: []
    extraArgs: {}
    extraContainers: []
    extraEnvFrom: []
    extraVolumeMounts: []
    extraVolumes: []
    initContainers: []
    jaegerReporterMaxQueueSize: null
    livenessProbe:
      httpGet:
        path: /ready
        port: http-metrics
      initialDelaySeconds: 45
    nodeSelector: {}
    persistence:
      subPath: null
    podAnnotations: {}
    podDisruptionBudget:
      maxUnavailable: 1
    podLabels: {}
    priorityClassName: null
    readinessProbe:
      httpGet:
        path: /ready
        port: http-metrics
      initialDelaySeconds: 45
    replicas: 2
    resources:
      requests:
        cpu: 100m
        memory: 128Mi
    securityContext: {}
    service:
      annotations: {}
      extraPorts: []
      labels: {}
    strategy:
      rollingUpdate:
        maxSurge: 15%
        maxUnavailable: 0
      type: RollingUpdate
    terminationGracePeriodSeconds: 180
    tolerations: []
image:
  pullPolicy: IfNotPresent
  repository: grafana/mimir
  tag: 2.16.0
index-cache:
  affinity: {}
  allocatedMemory: 2048
  annotations: {}
  connectionLimit: 16384
  enabled: true
  extraArgs: {}
  extraContainers: []
  extraExtendedOptions: ""
  extraVolumeMounts: []
  extraVolumes: []
  initContainers: []
  maxItemMemory: 5
  nodeSelector: {}
  podAnnotations: {}
  podDisruptionBudget:
    maxUnavailable: 1
  podLabels: {}
  podManagementPolicy: Parallel
  port: 11211
  priorityClassName: null
  replicas: 3
  resources: null
  service:
    annotations: {}
    extraPorts: []
    labels: {}
  statefulStrategy:
    type: RollingUpdate
  terminationGracePeriodSeconds: 30
  tolerations: []
  topologySpreadConstraints: {}
  volumeClaimTemplates: []
ingester:
  affinity:
    podAntiAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
      - labelSelector:
          matchExpressions:
          - key: target
            operator: In
            values:
            - ingester
        topologyKey: kubernetes.io/hostname
      - labelSelector:
          matchExpressions:
          - key: app.kubernetes.io/component
            operator: In
            values:
            - ingester
        topologyKey: kubernetes.io/hostname
  annotations: {}
  containerSecurityContext:
    allowPrivilegeEscalation: false
    capabilities:
      drop:
      - ALL
    readOnlyRootFilesystem: true
  enabled: true
  env: []
  extraArgs:
    log.level: debug
  extraContainers: []
  extraEnvFrom: []
  extraVolumeMounts: []
  extraVolumes: []
  image: null
  initContainers: []
  jaegerReporterMaxQueueSize: 1000
  nodeSelector: {}
  persistentVolume:
    accessModes:
    - ReadWriteOnce
    annotations: {}
    enableRetentionPolicy: false
    enabled: true
    name: storage
    size: 50Gi
    subPath: ""
    whenDeleted: Retain
    whenScaled: Retain
  podAnnotations: {}
  podDisruptionBudget:
    maxUnavailable: 1
  podLabels: {}
  podManagementPolicy: Parallel
  priorityClassName: null
  readinessProbe:
    httpGet:
      path: /ready
      port: http-metrics
    initialDelaySeconds: 60
  replicas: 2
  resources:
    limits:
      memory: 12Gi
    requests:
      cpu: 3.5
      memory: 8Gi
  ring:
    replication-factor: 3
  schedulerName: ""
  securityContext: {}
  service:
    annotations: {}
    extraPorts: []
    internalTrafficPolicy: Cluster
    labels: {}
    type: ClusterIP
  statefulSet:
    enabled: true
  statefulStrategy:
    type: RollingUpdate
  terminationGracePeriodSeconds: 1200
  tolerations: []
  topologySpreadConstraints:
    maxSkew: 1
    topologyKey: kubernetes.io/hostname
    whenUnsatisfiable: ScheduleAnyway
  zoneAwareReplication:
    enabled: false
    maxUnavailable: 50
    migration:
      enabled: false
      excludeDefaultZone: false
      readPath: false
      replicas: 0
      scaleDownDefaultZone: false
      writePath: false
    topologyKey: null
    zones:
    - extraAffinity: {}
      name: zone-a
      nodeSelector: null
      storageClass: null
    - extraAffinity: {}
      name: zone-b
      nodeSelector: null
      storageClass: null
    - extraAffinity: {}
      name: zone-c
      nodeSelector: null
      storageClass: null
ingress:
  annotations: {}
  enabled: false
  hosts:
  - mimir.example.com
  paths:
    alertmanager-headless:
    - path: /alertmanager
    - path: /multitenant_alertmanager/status
    - path: /multitenant_alertmanager/configs
    - path: /api/v1/alerts
    compactor:
    - path: /api/v1/upload/block/
    distributor-headless:
    - path: /distributor
    - path: /api/v1/push
    - path: /otlp/v1/metrics
    query-frontend:
    - path: /prometheus
    - path: /api/v1/status/buildinfo
    ruler:
    - path: /prometheus/config/v1/rules
    - path: /prometheus/api/v1/rules
    - path: /prometheus/api/v1/alerts
kedaAutoscaling:
  authentication:
    authModes: ""
    enabled: false
    secretTargetRef: []
  customHeaders: {}
  ignoreNullValues: true
  pollingInterval: 10
  prometheusAddress: ""
  toPromQLLabelSelector: {}
  unsafeSsl: false
kubeVersionOverride: null
kubectlImage:
  pullPolicy: IfNotPresent
  registry: docker.io
  repository: bitnami/kubectl
  tag: latest
license:
  contents: NOTAVALIDLICENSE
  external: false
  secretName: '{{ include "mimir.resourceName" (dict "ctx" . "component" "license")
    }}'
memcached:
  containerSecurityContext:
    allowPrivilegeEscalation: false
    capabilities:
      drop:
      - ALL
    readOnlyRootFilesystem: true
  image:
    pullPolicy: IfNotPresent
    repository: memcached
    tag: 1.6.37-alpine
  podSecurityContext: {}
  priorityClassName: null
memcachedExporter:
  containerSecurityContext:
    allowPrivilegeEscalation: false
    capabilities:
      drop:
      - ALL
    readOnlyRootFilesystem: true
  enabled: true
  extraArgs: {}
  image:
    pullPolicy: IfNotPresent
    repository: prom/memcached-exporter
    tag: v0.15.1
  resources:
    limits: {}
    requests: {}
metaMonitoring:
  dashboards:
    annotations:
      k8s-sidecar-target-directory: /tmp/dashboards/Mimir Dashboards
    enabled: false
    labels:
      grafana_dashboard: "1"
    namespace: null
  grafanaAgent:
    annotations: {}
    containerSecurityContext: null
    enabled: false
    imageRepo: null
    installOperator: false
    labels: {}
    logs:
      additionalClientConfigs: []
      clusterLabel: ""
      enabled: true
      remote:
        auth:
          passwordSecretKey: ""
          passwordSecretName: ""
          tenantId: ""
          username: ""
        url: ""
    metrics:
      additionalRemoteWriteConfigs: []
      enabled: true
      remote:
        auth:
          passwordSecretKey: ""
          passwordSecretName: ""
          username: ""
        headers: {}
        sigv4: {}
        url: ""
      scrapeInterval: 60s
      scrapeK8s:
        enabled: true
        kubeStateMetrics:
          labelSelectors:
            app.kubernetes.io/name: kube-state-metrics
          namespace: kube-system
          service:
            port: http-metrics
    namespace: ""
    nodeSelector: {}
    podSecurityContext: null
    resources: null
    tolerations: []
    topologySpreadConstraints:
    - maxSkew: 1
      topologyKey: kubernetes.io/hostname
      whenUnsatisfiable: ScheduleAnyway
  prometheusRule:
    annotations: {}
    enabled: false
    groups: []
    labels: {}
    mimirAlerts: false
    mimirRules: false
    namespace: null
  serviceMonitor:
    annotations: {}
    clusterLabel: ""
    enabled: false
    interval: null
    labels: {}
    metricRelabelings: []
    namespace: null
    namespaceSelector: null
    relabelings: []
    scheme: http
    scrapeTimeout: null
    tlsConfig: null
metadata-cache:
  affinity: {}
  allocatedMemory: 512
  annotations: {}
  connectionLimit: 16384
  enabled: true
  extraArgs: {}
  extraContainers: []
  extraExtendedOptions: ""
  extraVolumeMounts: []
  extraVolumes: []
  initContainers: []
  maxItemMemory: 1
  nodeSelector: {}
  podAnnotations: {}
  podDisruptionBudget:
    maxUnavailable: 1
  podLabels: {}
  podManagementPolicy: Parallel
  port: 11211
  priorityClassName: null
  replicas: 3
  resources: null
  service:
    annotations: {}
    extraPorts: []
    labels: {}
  statefulStrategy:
    type: RollingUpdate
  terminationGracePeriodSeconds: 30
  tolerations: []
  topologySpreadConstraints: {}
  volumeClaimTemplates: []
mimir:
  config: |
    usage_stats:
      installation_mode: helm

    activity_tracker:
      filepath: /active-query-tracker/activity.log

    {{- if .Values.enterprise.enabled }}
    admin_api:
      leader_election:
        enabled: true
        ring:
          kvstore:
            store: "memberlist"

    admin_client:
      storage:
      {{- if .Values.minio.enabled }}
        type: s3
        s3:
          access_key_id: {{ .Values.minio.rootUser }}
          bucket_name: enterprise-metrics-admin
          endpoint: {{ template "minio.fullname" .Subcharts.minio }}.{{ .Release.Namespace }}.svc:{{ .Values.minio.service.port }}
          insecure: true
          secret_access_key: {{ .Values.minio.rootPassword }}
      {{- end }}
      {{- if (index .Values "admin-cache" "enabled") }}
        cache:
          backend: memcached
          memcached:
            addresses: {{ include "mimir.adminCacheAddress" . }}
            max_item_size: {{ mul (index .Values "admin-cache").maxItemMemory 1024 1024 }}
      {{- end }}
    {{- end }}

    alertmanager:
      data_dir: /data
      enable_api: true
      external_url: /alertmanager
      {{- if .Values.alertmanager.zoneAwareReplication.enabled }}
      sharding_ring:
        zone_awareness_enabled: true
      {{- end }}
      {{- if .Values.alertmanager.fallbackConfig }}
      fallback_config_file: /configs/alertmanager_fallback_config.yaml
      {{- end }}

    {{- if .Values.minio.enabled }}
    alertmanager_storage:
      backend: s3
      s3:
        access_key_id: {{ .Values.minio.rootUser }}
        bucket_name: {{ include "mimir.minioBucketPrefix" . }}-ruler
        endpoint: {{ template "minio.fullname" .Subcharts.minio }}.{{ .Release.Namespace }}.svc:{{ .Values.minio.service.port }}
        insecure: true
        secret_access_key: {{ .Values.minio.rootPassword }}
    {{- end }}

    {{- if .Values.enterprise.enabled }}
    auth:
      type: enterprise
      admin:
        pass_access_policy_name: true
        pass_token_name: true
    {{- end }}

    # This configures how the store-gateway synchronizes blocks stored in the bucket. It uses Minio by default for getting started (configured via flags) but this should be changed for production deployments.
    blocks_storage:
      backend: s3
      bucket_store:
        {{- if index .Values "chunks-cache" "enabled" }}
        chunks_cache:
          backend: memcached
          memcached:
            addresses: {{ include "mimir.chunksCacheAddress" . }}
            max_item_size: {{ mul (index .Values "chunks-cache").maxItemMemory 1024 1024 }}
            timeout: 750ms
            max_idle_connections: 150
        {{- end }}
        {{- if index .Values "index-cache" "enabled" }}
        index_cache:
          backend: memcached
          memcached:
            addresses: {{ include "mimir.indexCacheAddress" . }}
            max_item_size: {{ mul (index .Values "index-cache").maxItemMemory 1024 1024 }}
            timeout: 750ms
            max_idle_connections: 150
        {{- end }}
        {{- if index .Values "metadata-cache" "enabled" }}
        metadata_cache:
          backend: memcached
          memcached:
            addresses: {{ include "mimir.metadataCacheAddress" . }}
            max_item_size: {{ mul (index .Values "metadata-cache").maxItemMemory 1024 1024 }}
            max_idle_connections: 150
        {{- end }}
        sync_dir: /data/tsdb-sync
      {{- if .Values.minio.enabled }}
      s3:
        access_key_id: {{ .Values.minio.rootUser }}
        bucket_name: {{ include "mimir.minioBucketPrefix" . }}-tsdb
        endpoint: {{ template "minio.fullname" .Subcharts.minio }}.{{ .Release.Namespace }}.svc:{{ .Values.minio.service.port }}
        insecure: true
        secret_access_key: {{ .Values.minio.rootPassword }}
      {{- end }}
      tsdb:
        dir: /data/tsdb
        head_compaction_interval: 15m
        wal_replay_concurrency: 3

    {{- if .Values.enterprise.enabled }}
    cluster_name: "{{ .Release.Name }}"
    {{- end }}

    compactor:
      compaction_interval: 30m
      deletion_delay: 2h
      max_closing_blocks_concurrency: 2
      max_opening_blocks_concurrency: 4
      symbols_flushers_concurrency: 4
      first_level_compaction_wait_period: 25m
      data_dir: "/data"
      sharding_ring:
        wait_stability_min_duration: 1m
        heartbeat_period: 1m
        heartbeat_timeout: 4m

    distributor:
      ring:
        heartbeat_period: 1m
        heartbeat_timeout: 4m

    frontend:
      parallelize_shardable_queries: true
      {{- if index .Values "results-cache" "enabled" }}
      results_cache:
        backend: memcached
        memcached:
          timeout: 500ms
          addresses: {{ include "mimir.resultsCacheAddress" . }}
          max_item_size: {{ mul (index .Values "results-cache").maxItemMemory 1024 1024 }}
      cache_results: true
      query_sharding_target_series_per_shard: 2500
      {{- end }}
      {{- if and .Values.query_scheduler.enabled (not .Values.federation_frontend.disableOtherComponents) }}
      scheduler_address: {{ template "mimir.fullname" . }}-query-scheduler-headless.{{ .Release.Namespace }}.svc:{{ include "mimir.serverGrpcListenPort" . }}
      {{- end }}
      {{- if .Values.enterprise.enabled }}
      log_query_request_headers: X-Access-Policy-Name,X-Token-Name
      {{- end }}

    frontend_worker:
      grpc_client_config:
        max_send_msg_size: 419430400 # 400MiB
      {{- if .Values.query_scheduler.enabled }}
      scheduler_address: {{ template "mimir.fullname" . }}-query-scheduler-headless.{{ .Release.Namespace }}.svc:{{ include "mimir.serverGrpcListenPort" . }}
      {{- else }}
      frontend_address: {{ template "mimir.fullname" . }}-query-frontend-headless.{{ .Release.Namespace }}.svc:{{ include "mimir.serverGrpcListenPort" . }}
      {{- end }}

    {{- if and .Values.enterprise.enabled }}
    gateway:
      proxy:
        admin_api:
          url: http://{{ template "mimir.fullname" . }}-admin-api.{{ .Release.Namespace }}.svc:{{ include "mimir.serverHttpListenPort" . }}
        alertmanager:
          url: http://{{ template "mimir.fullname" . }}-alertmanager-headless.{{ .Release.Namespace }}.svc:{{ include "mimir.serverHttpListenPort" . }}
        compactor:
          url: http://{{ template "mimir.fullname" . }}-compactor.{{ .Release.Namespace }}.svc:{{ include "mimir.serverHttpListenPort" . }}
        default:
          url: http://{{ template "mimir.fullname" . }}-admin-api.{{ .Release.Namespace }}.svc:{{ include "mimir.serverHttpListenPort" . }}
        {{- if and .Values.distributor.enabled (not .Values.federation_frontend.disableOtherComponents) }}
        distributor:
          url: dns:///{{ template "mimir.fullname" . }}-distributor-headless.{{ .Release.Namespace }}.svc.{{ .Values.global.clusterDomain }}:{{ include "mimir.serverGrpcListenPort" . }}
        {{- end }}
        ingester:
          url: http://{{ template "mimir.fullname" . }}-ingester-headless.{{ .Release.Namespace }}.svc:{{ include "mimir.serverHttpListenPort" . }}
        query_frontend:
        {{ if .Values.federation_frontend.enabled }}
          url: http://{{ template "mimir.fullname" . }}-federation-frontend.{{ .Release.Namespace }}.svc:{{ include "mimir.serverHttpListenPort" . }}
        {{ else }}
          url: http://{{ template "mimir.fullname" . }}-query-frontend.{{ .Release.Namespace }}.svc:{{ include "mimir.serverHttpListenPort" . }}
        {{ end }}
        ruler:
          url: http://{{ template "mimir.fullname" . }}-ruler.{{ .Release.Namespace }}.svc:{{ include "mimir.serverHttpListenPort" . }}
        store_gateway:
          url: http://{{ template "mimir.fullname" . }}-store-gateway-headless.{{ .Release.Namespace }}.svc:{{ include "mimir.serverHttpListenPort" . }}
        {{- if and .Values.enterprise.enabled .Values.graphite.enabled }}
        graphite_write_proxy:
          url: http://{{ template "mimir.fullname" . }}-graphite-write-proxy.{{ .Release.Namespace }}.svc:{{ include "mimir.serverHttpListenPort" . }}
        graphite_querier:
          url: http://{{ template "mimir.fullname" . }}-graphite-querier.{{ .Release.Namespace }}.svc:{{ include "mimir.serverHttpListenPort" . }}
        {{- end}}
    {{- end }}

    ingester:
      ring:
        final_sleep: 0s
        num_tokens: 512
        tokens_file_path: /data/tokens
        unregister_on_shutdown: false
        heartbeat_period: 2m
        heartbeat_timeout: 10m
        {{- if .Values.ingester.zoneAwareReplication.enabled }}
        zone_awareness_enabled: true
        {{- end }}

    ingester_client:
      grpc_client_config:
        max_recv_msg_size: 104857600
        max_send_msg_size: 104857600

    {{- if .Values.enterprise.enabled }}
    instrumentation:
      enabled: {{ and .Values.distributor.enabled (not .Values.federation_frontend.disableOtherComponents) }}
    {{- if and .Values.distributor.enabled (not .Values.federation_frontend.disableOtherComponents) }}
      distributor_client:
        address: dns:///{{ template "mimir.fullname" . }}-distributor-headless.{{ .Release.Namespace }}.svc.{{ .Values.global.clusterDomain }}:{{ include "mimir.serverGrpcListenPort" . }}
    {{- end }}

    license:
      path: "/license/license.jwt"
    {{- end }}

    limits:
      # Limit queries to 500 days. You can override this on a per-tenant basis.
      max_total_query_length: 12000h
      # Adjust max query parallelism to 16x sharding, without sharding we can run 15d queries fully in parallel.
      # With sharding we can further shard each day another 16 times. 15 days * 16 shards = 240 subqueries.
      max_query_parallelism: 240
      # Avoid caching results newer than 10m because some samples can be delayed
      # This presents caching incomplete results
      max_cache_freshness: 10m

    memberlist:
      abort_if_cluster_join_fails: false
      compression_enabled: false
      join_members:
      - dns+{{ include "mimir.fullname" . }}-gossip-ring.{{ .Release.Namespace }}.svc.{{ .Values.global.clusterDomain }}:{{ include "mimir.memberlistBindPort" . }}

    querier:
      # With query sharding we run more but smaller queries. We must strike a balance
      # which allows us to process more sharded queries in parallel when requested, but not overload
      # queriers during non-sharded queries.
      max_concurrent: 16

    query_scheduler:
      # Increase from default of 100 to account for queries created by query sharding
      max_outstanding_requests_per_tenant: 800

    ruler:
      alertmanager_url: dnssrvnoa+http://_http-metrics._tcp.{{ template "mimir.fullname" . }}-alertmanager-headless.{{ .Release.Namespace }}.svc.{{ .Values.global.clusterDomain }}/alertmanager
      enable_api: true
      rule_path: /data
      {{- if .Values.ruler.remoteEvaluationDedicatedQueryPath }}
      query_frontend:
        address: dns:///{{ template "mimir.fullname" . }}-ruler-query-frontend.{{ .Release.Namespace }}.svc:{{ include "mimir.serverGrpcListenPort" .  }}
      {{- end }}

    {{- if or (.Values.minio.enabled) (index .Values "metadata-cache" "enabled") }}
    ruler_storage:
      {{- if .Values.minio.enabled }}
      backend: s3
      s3:
        endpoint: {{ template "minio.fullname" .Subcharts.minio }}.{{ .Release.Namespace }}.svc:{{ .Values.minio.service.port }}
        bucket_name: {{ include "mimir.minioBucketPrefix" . }}-ruler
        access_key_id: {{ .Values.minio.rootUser }}
        secret_access_key: {{ .Values.minio.rootPassword }}
        insecure: true
      {{- end }}
      {{- if index .Values "metadata-cache" "enabled" }}
      cache:
        backend: memcached
        memcached:
          addresses: {{ include "mimir.metadataCacheAddress" . }}
          max_item_size: {{ mul (index .Values "metadata-cache").maxItemMemory 1024 1024 }}
      {{- end }}
    {{- end }}

    {{- if not .Values.federation_frontend.disableOtherComponents }}
    runtime_config:
      file: /var/{{ include "mimir.name" . }}/runtime.yaml
    {{- end }}

    store_gateway:
      sharding_ring:
        heartbeat_period: 1m
        heartbeat_timeout: 10m
        wait_stability_min_duration: 1m
        {{- if .Values.store_gateway.zoneAwareReplication.enabled }}
        kvstore:
          prefix: multi-zone/
        {{- end }}
        tokens_file_path: /data/tokens
        unregister_on_shutdown: false
        {{- if .Values.store_gateway.zoneAwareReplication.enabled }}
        zone_awareness_enabled: true
        {{- end }}

    {{- if and .Values.enterprise.enabled .Values.graphite.enabled }}
    graphite:
      enabled: true

      write_proxy:
        distributor_client:
          address: dns:///{{ template "mimir.fullname" . }}-distributor.{{ .Release.Namespace }}.svc:{{ include "mimir.serverGrpcListenPort" .  }}

      querier:
        remote_read:
          query_address: http://{{ template "mimir.fullname" . }}-query-frontend.{{ .Release.Namespace }}.svc:{{ include "mimir.serverHttpListenPort" .  }}/prometheus
        proxy_bad_requests: false

        schemas:
          default_storage_schemas_file: /etc/graphite-proxy/storage-schemas.conf
          default_storage_aggregations_file: /etc/graphite-proxy/storage-aggregations.conf
        aggregation_cache:
          memcached:
            addresses: dnssrvnoa+{{ template "mimir.fullname" . }}-gr-aggr-cache.{{ .Release.Namespace}}.svc:11211
            timeout: 1s
        metric_name_cache:
          memcached:
            addresses: dnssrvnoa+{{ template "mimir.fullname" . }}-gr-metricname-cache.{{ .Release.Namespace}}.svc:11211
            timeout: 1s
    {{- end}}
  structuredConfig:
    blocks_storage:
      backend: s3
      s3:
        bucket_name: mimir-staging-testing
        endpoint: s3.ap-south-1.amazonaws.com
        region: ap-south-1
minio:
  buckets:
  - name: mimir-tsdb
    policy: none
    purge: false
  - name: mimir-ruler
    policy: none
    purge: false
  - name: enterprise-metrics-tsdb
    policy: none
    purge: false
  - name: enterprise-metrics-admin
    policy: none
    purge: false
  - name: enterprise-metrics-ruler
    policy: none
    purge: false
  configPathmc: /tmp/minio/mc/
  enabled: false
  mode: standalone
  persistence:
    size: 5Gi
  resources:
    requests:
      cpu: 100m
      memory: 128Mi
  rootPassword: supersecret
  rootUser: grafana-mimir
nameOverride: null
nginx:
  affinity: ""
  annotations: {}
  autoscaling:
    enabled: false
    maxReplicas: 3
    minReplicas: 1
    targetCPUUtilizationPercentage: 60
    targetMemoryUtilizationPercentage: null
  basicAuth:
    enabled: false
    existingSecret: null
    htpasswd: '{{ htpasswd (required "''nginx.basicAuth.username'' is required" .Values.nginx.basicAuth.username)
      (required "''nginx.basicAuth.password'' is required" .Values.nginx.basicAuth.password)
      }}'
    password: null
    username: null
  containerSecurityContext:
    allowPrivilegeEscalation: false
    capabilities:
      drop:
      - ALL
    readOnlyRootFilesystem: true
  deploymentStrategy:
    rollingUpdate:
      maxSurge: 15%
      maxUnavailable: 0
    type: RollingUpdate
  enabled: true
  extraArgs: {}
  extraContainers: []
  extraEnv: []
  extraEnvFrom: []
  extraVolumeMounts: []
  extraVolumes: []
  image:
    pullPolicy: IfNotPresent
    registry: docker.io
    repository: nginxinc/nginx-unprivileged
    tag: 1.27-alpine
  ingress:
    annotations: {}
    enabled: false
    hosts:
    - host: nginx.mimir.example.com
      paths:
      - path: /
    tls:
    - hosts:
      - nginx.mimir.example.com
      secretName: mimir-nginx-tls
  nginxConfig:
    accessLogEnabled: true
    errorLogLevel: error
    file: |
      worker_processes  5;  ## Default: 1
      error_log  /dev/stderr {{ .Values.nginx.nginxConfig.errorLogLevel }};
      pid        /tmp/nginx.pid;
      worker_rlimit_nofile 8192;

      events {
        worker_connections  4096;  ## Default: 1024
      }

      http {
        client_body_temp_path /tmp/client_temp;
        proxy_temp_path       /tmp/proxy_temp_path;
        fastcgi_temp_path     /tmp/fastcgi_temp;
        uwsgi_temp_path       /tmp/uwsgi_temp;
        scgi_temp_path        /tmp/scgi_temp;

        default_type application/octet-stream;
        log_format   {{ .Values.nginx.nginxConfig.logFormat }}

        {{- if .Values.nginx.verboseLogging }}
        access_log   /dev/stderr  main;
        {{- else }}

        map $status $loggable {
          ~^[23]  0;
          default 1;
        }
        access_log   {{ .Values.nginx.nginxConfig.accessLogEnabled | ternary "/dev/stderr  main  if=$loggable;" "off;" }}
        {{- end }}

        sendfile           on;
        tcp_nopush         on;
        proxy_http_version 1.1;

        {{- if .Values.nginx.nginxConfig.resolver }}
        resolver {{ .Values.nginx.nginxConfig.resolver }};
        {{- else }}
        resolver {{ .Values.global.dnsService }}.{{ .Values.global.dnsNamespace }}.svc.{{ .Values.global.clusterDomain }};
        {{- end }}

        {{- with .Values.nginx.nginxConfig.httpSnippet }}
        {{ . | nindent 2 }}
        {{- end }}

        # Ensure that X-Scope-OrgID is always present, default to the no_auth_tenant for backwards compatibility when multi-tenancy was turned off.
        map $http_x_scope_orgid $ensured_x_scope_orgid {
          default $http_x_scope_orgid;
          "" "{{ include "mimir.noAuthTenant" . }}";
        }

        map $http_x_scope_orgid $has_multiple_orgid_headers {
          default 0;
          "~^.+,.+$" 1;
        }

        proxy_read_timeout 300;
        server {
          listen 8080;
          listen [::]:8080;

          {{- if .Values.nginx.basicAuth.enabled }}
          auth_basic           "Mimir";
          auth_basic_user_file /etc/nginx/secrets/.htpasswd;
          {{- end }}

          if ($has_multiple_orgid_headers = 1) {
              return 400 'Sending multiple X-Scope-OrgID headers is not allowed. Use a single header with | as separator instead.';
          }

          location = / {
            return 200 'OK';
            auth_basic off;
          }

          proxy_set_header X-Scope-OrgID $ensured_x_scope_orgid;

          # Distributor endpoints
          location /distributor {
            set $distributor {{ template "mimir.fullname" . }}-distributor-headless.{{ .Release.Namespace }}.svc.{{ .Values.global.clusterDomain }};
            proxy_pass      http://$distributor:{{ include "mimir.serverHttpListenPort" . }}$request_uri;
          }
          location = /api/v1/push {
            set $distributor {{ template "mimir.fullname" . }}-distributor-headless.{{ .Release.Namespace }}.svc.{{ .Values.global.clusterDomain }};
            proxy_pass      http://$distributor:{{ include "mimir.serverHttpListenPort" . }}$request_uri;
          }
          location /otlp/v1/metrics {
            set $distributor {{ template "mimir.fullname" . }}-distributor-headless.{{ .Release.Namespace }}.svc.{{ .Values.global.clusterDomain }};
            proxy_pass      http://$distributor:{{ include "mimir.serverHttpListenPort" . }}$request_uri;
          }

          # Alertmanager endpoints
          location {{ template "mimir.alertmanagerHttpPrefix" . }} {
            set $alertmanager {{ template "mimir.fullname" . }}-alertmanager-headless.{{ .Release.Namespace }}.svc.{{ .Values.global.clusterDomain }};
            proxy_pass      http://$alertmanager:{{ include "mimir.serverHttpListenPort" . }}$request_uri;
          }
          location = /multitenant_alertmanager/status {
            set $alertmanager {{ template "mimir.fullname" . }}-alertmanager-headless.{{ .Release.Namespace }}.svc.{{ .Values.global.clusterDomain }};
            proxy_pass      http://$alertmanager:{{ include "mimir.serverHttpListenPort" . }}$request_uri;
          }
          location = /multitenant_alertmanager/configs {
            set $alertmanager {{ template "mimir.fullname" . }}-alertmanager-headless.{{ .Release.Namespace }}.svc.{{ .Values.global.clusterDomain }};
            proxy_pass      http://$alertmanager:{{ include "mimir.serverHttpListenPort" . }}$request_uri;
          }
          location = /api/v1/alerts {
            set $alertmanager {{ template "mimir.fullname" . }}-alertmanager-headless.{{ .Release.Namespace }}.svc.{{ .Values.global.clusterDomain }};
            proxy_pass      http://$alertmanager:{{ include "mimir.serverHttpListenPort" . }}$request_uri;
          }

          # Ruler endpoints
          location {{ template "mimir.prometheusHttpPrefix" . }}/config/v1/rules {
            set $ruler {{ template "mimir.fullname" . }}-ruler.{{ .Release.Namespace }}.svc.{{ .Values.global.clusterDomain }};
            proxy_pass      http://$ruler:{{ include "mimir.serverHttpListenPort" . }}$request_uri;
          }
          location {{ template "mimir.prometheusHttpPrefix" . }}/api/v1/rules {
            set $ruler {{ template "mimir.fullname" . }}-ruler.{{ .Release.Namespace }}.svc.{{ .Values.global.clusterDomain }};
            proxy_pass      http://$ruler:{{ include "mimir.serverHttpListenPort" . }}$request_uri;
          }

          location {{ template "mimir.prometheusHttpPrefix" . }}/api/v1/alerts {
            set $ruler {{ template "mimir.fullname" . }}-ruler.{{ .Release.Namespace }}.svc.{{ .Values.global.clusterDomain }};
            proxy_pass      http://$ruler:{{ include "mimir.serverHttpListenPort" . }}$request_uri;
          }
          location = /ruler/ring {
            set $ruler {{ template "mimir.fullname" . }}-ruler.{{ .Release.Namespace }}.svc.{{ .Values.global.clusterDomain }};
            proxy_pass      http://$ruler:{{ include "mimir.serverHttpListenPort" . }}$request_uri;
          }

          # Rest of {{ template "mimir.prometheusHttpPrefix" . }} goes to the query frontend
          location {{ template "mimir.prometheusHttpPrefix" . }} {
            set $query_frontend {{ template "mimir.fullname" . }}-query-frontend.{{ .Release.Namespace }}.svc.{{ .Values.global.clusterDomain }};
            proxy_pass      http://$query_frontend:{{ include "mimir.serverHttpListenPort" . }}$request_uri;
          }

          # Buildinfo endpoint can go to any component
          location = /api/v1/status/buildinfo {
            set $query_frontend {{ template "mimir.fullname" . }}-query-frontend.{{ .Release.Namespace }}.svc.{{ .Values.global.clusterDomain }};
            proxy_pass      http://$query_frontend:{{ include "mimir.serverHttpListenPort" . }}$request_uri;
          }

          # Compactor endpoint for uploading blocks
          location /api/v1/upload/block/ {
            set $compactor {{ template "mimir.fullname" . }}-compactor.{{ .Release.Namespace }}.svc.{{ .Values.global.clusterDomain }};
            proxy_pass      http://$compactor:{{ include "mimir.serverHttpListenPort" . }}$request_uri;
          }

          {{- with .Values.nginx.nginxConfig.serverSnippet }}
          {{ . | nindent 4 }}
          {{- end }}
        }
      }
    httpSnippet: ""
    logFormat: |-
      main '$remote_addr - $remote_user [$time_local]  $status '
              '"$request" $body_bytes_sent "$http_referer" '
              '"$http_user_agent" "$http_x_forwarded_for"';
    resolver: null
    serverSnippet: ""
  nodeSelector: {}
  podAnnotations: {}
  podDisruptionBudget:
    maxUnavailable: 1
  podLabels: {}
  podSecurityContext: {}
  priorityClassName: null
  readinessProbe:
    httpGet:
      path: /
      port: http-metric
    initialDelaySeconds: 15
    timeoutSeconds: 1
  replicas: 1
  resources:
    limits:
      memory: 731Mi
    requests:
      cpu: 1
      memory: 512Mi
  route:
    annotations: {}
    enabled: false
    host: nginx.mimir.example.com
    tls:
      termination: edge
  service:
    annotations: {}
    clusterIP: null
    extraPorts: []
    internalTrafficPolicy: Cluster
    labels: {}
    loadBalancerIP: null
    nodePort: null
    port: 80
    type: ClusterIP
  terminationGracePeriodSeconds: 30
  tolerations: []
  topologySpreadConstraints:
    maxSkew: 1
    topologyKey: kubernetes.io/hostname
    whenUnsatisfiable: ScheduleAnyway
  verboseLogging: true
overrides_exporter:
  affinity: {}
  annotations: {}
  containerSecurityContext:
    allowPrivilegeEscalation: false
    capabilities:
      drop:
      - ALL
    readOnlyRootFilesystem: true
  enabled: true
  env: []
  extraArgs: {}
  extraContainers: []
  extraEnvFrom: []
  extraVolumeMounts: []
  extraVolumes: []
  image: null
  initContainers: []
  jaegerReporterMaxQueueSize: null
  livenessProbe:
    httpGet:
      path: /ready
      port: http-metrics
    initialDelaySeconds: 45
  nodeSelector: {}
  persistence:
    subPath: null
  podAnnotations: {}
  podDisruptionBudget:
    maxUnavailable: 1
  podLabels: {}
  priorityClassName: null
  readinessProbe:
    httpGet:
      path: /ready
      port: http-metrics
    initialDelaySeconds: 45
  replicas: 1
  resources:
    limits:
      memory: 128Mi
    requests:
      cpu: 100m
      memory: 128Mi
  securityContext: {}
  service:
    annotations: {}
    extraPorts: []
    internalTrafficPolicy: Cluster
    labels: {}
    type: ClusterIP
  strategy:
    rollingUpdate:
      maxSurge: 15%
      maxUnavailable: 0
    type: RollingUpdate
  terminationGracePeriodSeconds: 30
  tolerations: []
  topologySpreadConstraints: {}
provisioner:
  additionalTenants: []
  affinity: {}
  annotations: {}
  apiUrl: http://{{ template "mimir.fullname" . }}-admin-api.{{ .Release.Namespace
    }}.svc:{{ include "mimir.serverHttpListenPort" . }}
  enabled: false
  env: []
  extraVolumeMounts: []
  hookType: post-install,post-upgrade
  image:
    pullPolicy: IfNotPresent
    registry: us-docker.pkg.dev
    repository: grafanalabs-global/docker-enterprise-provisioner-prod/enterprise-provisioner
    tag: latest
  labels: {}
  nodeSelector: {}
  priorityClassName: null
  provisionedSecretPrefix: '{{ template "mimir.fullname" . }}'
  securityContext:
    fsGroup: 10001
    runAsGroup: 10001
    runAsNonRoot: true
    runAsUser: 10001
  tolerations: []
querier:
  affinity: {}
  annotations: {}
  containerSecurityContext:
    allowPrivilegeEscalation: false
    capabilities:
      drop:
      - ALL
    readOnlyRootFilesystem: true
  enabled: true
  env: []
  extraArgs: {}
  extraContainers: []
  extraEnvFrom: []
  extraVolumeMounts: []
  extraVolumes: []
  image: null
  initContainers: []
  jaegerReporterMaxQueueSize: 5000
  kedaAutoscaling:
    behavior:
      scaleDown:
        policies:
        - periodSeconds: 120
          type: Percent
          value: 10
        stabilizationWindowSeconds: 600
      scaleUp:
        policies:
        - periodSeconds: 120
          type: Percent
          value: 50
        - periodSeconds: 120
          type: Pods
          value: 15
        stabilizationWindowSeconds: 60
    enabled: false
    maxReplicaCount: 10
    minReplicaCount: 1
    predictiveScalingEnabled: false
    predictiveScalingLookback: 30m
    predictiveScalingPeriod: 6d23h30m
    preserveReplicas: false
    querySchedulerInflightRequestsThreshold: 12
  nodeSelector: {}
  persistence:
    subPath: null
  podAnnotations: {}
  podDisruptionBudget:
    maxUnavailable: 1
  podLabels: {}
  priorityClassName: null
  readinessProbe:
    httpGet:
      path: /ready
      port: http-metrics
    initialDelaySeconds: 45
  replicas: 1
  resources:
    limits:
      memory: 5.6Gi
    requests:
      cpu: 2
      memory: 4Gi
  securityContext: {}
  service:
    annotations: {}
    extraPorts: []
    internalTrafficPolicy: Cluster
    labels: {}
    type: ClusterIP
  strategy:
    rollingUpdate:
      maxSurge: 15%
      maxUnavailable: 0
    type: RollingUpdate
  terminationGracePeriodSeconds: 180
  tolerations: []
  topologySpreadConstraints:
    maxSkew: 1
    topologyKey: kubernetes.io/hostname
    whenUnsatisfiable: ScheduleAnyway
query_frontend:
  affinity: {}
  annotations: {}
  containerSecurityContext:
    allowPrivilegeEscalation: false
    capabilities:
      drop:
      - ALL
    readOnlyRootFilesystem: true
  enabled: true
  env: []
  extraArgs: {}
  extraContainers: []
  extraEnvFrom: []
  extraVolumeMounts: []
  extraVolumes: []
  image: null
  initContainers: []
  jaegerReporterMaxQueueSize: 5000
  kedaAutoscaling:
    behavior:
      scaleDown:
        policies:
        - periodSeconds: 60
          type: Percent
          value: 10
    enabled: false
    maxReplicaCount: 10
    minReplicaCount: 1
    preserveReplicas: false
    targetCPUUtilizationPercentage: 75
    targetMemoryUtilizationPercentage: 100
  nodeSelector: {}
  persistence:
    subPath: null
  podAnnotations: {}
  podDisruptionBudget:
    maxUnavailable: 1
  podLabels: {}
  priorityClassName: null
  readinessProbe:
    httpGet:
      path: /ready
      port: http-metrics
    initialDelaySeconds: 45
  replicas: 1
  resources:
    limits:
      memory: 2.8Gi
    requests:
      cpu: 2
      memory: 2Gi
  securityContext: {}
  service:
    annotations: {}
    extraPorts: []
    internalTrafficPolicy: Cluster
    labels: {}
    type: ClusterIP
  strategy:
    rollingUpdate:
      maxSurge: 15%
      maxUnavailable: 0
    type: RollingUpdate
  terminationGracePeriodSeconds: 390
  tolerations: []
  topologySpreadConstraints:
    maxSkew: 1
    topologyKey: kubernetes.io/hostname
    whenUnsatisfiable: ScheduleAnyway
query_scheduler:
  affinity: {}
  annotations: {}
  containerSecurityContext:
    allowPrivilegeEscalation: false
    capabilities:
      drop:
      - ALL
    readOnlyRootFilesystem: true
  enabled: true
  env: []
  extraArgs: {}
  extraContainers: []
  extraEnvFrom: []
  extraVolumeMounts: []
  extraVolumes: []
  image: null
  initContainers: []
  jaegerReporterMaxQueueSize: null
  nodeSelector: {}
  persistence:
    subPath: null
  podAnnotations: {}
  podDisruptionBudget:
    maxUnavailable: 1
  podLabels: {}
  priorityClassName: null
  readinessProbe:
    httpGet:
      path: /ready
      port: http-metrics
    initialDelaySeconds: 45
  replicas: 2
  resources:
    requests:
      cpu: 100m
      memory: 128Mi
  securityContext: {}
  service:
    annotations: {}
    extraPorts: []
    internalTrafficPolicy: Cluster
    labels: {}
    type: ClusterIP
  strategy:
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 0
    type: RollingUpdate
  terminationGracePeriodSeconds: 180
  tolerations: []
  topologySpreadConstraints:
    maxSkew: 1
    topologyKey: kubernetes.io/hostname
    whenUnsatisfiable: ScheduleAnyway
rbac:
  create: true
  forcePSPOnKubernetes124: false
  podSecurityContext:
    fsGroup: 10001
    runAsGroup: 10001
    runAsNonRoot: true
    runAsUser: 10001
    seccompProfile:
      type: RuntimeDefault
  podSecurityPolicy:
    additionalVolumes: []
    allowPrivilegeEscalation: false
    fsGroup:
      ranges:
      - max: 65535
        min: 1
      rule: MustRunAs
    hostIPC: false
    hostNetwork: false
    hostPID: false
    privileged: false
    readOnlyRootFilesystem: true
    runAsUser:
      rule: MustRunAsNonRoot
    seLinux:
      rule: RunAsAny
    seccompProfile: runtime/default
    supplementalGroups:
      ranges:
      - max: 65535
        min: 1
      rule: MustRunAs
  type: psp
results-cache:
  affinity: {}
  allocatedMemory: 512
  annotations: {}
  connectionLimit: 16384
  enabled: true
  extraArgs: {}
  extraContainers: []
  extraExtendedOptions: ""
  extraVolumeMounts: []
  extraVolumes: []
  initContainers: []
  maxItemMemory: 5
  nodeSelector: {}
  podAnnotations: {}
  podDisruptionBudget:
    maxUnavailable: 1
  podLabels: {}
  podManagementPolicy: Parallel
  port: 11211
  priorityClassName: null
  replicas: 3
  resources: null
  service:
    annotations: {}
    extraPorts: []
    labels: {}
  statefulStrategy:
    type: RollingUpdate
  terminationGracePeriodSeconds: 30
  tolerations: []
  topologySpreadConstraints: {}
  volumeClaimTemplates: []
rollout_operator:
  affinity: {}
  enabled: true
  fullnameOverride: ""
  global:
    clusterDomain: cluster.local.
    commonLabels: {}
    dnsNamespace: kube-system
    dnsService: kube-dns
    extraEnv: []
    extraEnvFrom: []
    extraVolumeMounts: []
    extraVolumes: []
    podAnnotations: {}
    podLabels: {}
  hostAliases: []
  image:
    pullPolicy: IfNotPresent
    repository: grafana/rollout-operator
    tag: ""
  imagePullSecrets: []
  minReadySeconds: 10
  nameOverride: ""
  nodeSelector: {}
  podAnnotations: {}
  podLabels: {}
  podSecurityContext:
    fsGroup: 10001
    runAsGroup: 10001
    runAsNonRoot: true
    runAsUser: 10001
    seccompProfile:
      type: RuntimeDefault
  priorityClassName: ""
  resources:
    limits:
      memory: 200Mi
    requests:
      cpu: 100m
      memory: 100Mi
  securityContext:
    allowPrivilegeEscalation: false
    capabilities:
      drop:
      - ALL
    readOnlyRootFilesystem: true
  serviceAccount:
    annotations: {}
    create: true
    name: ""
  serviceMonitor:
    annotations: {}
    enabled: false
    interval: null
    labels: {}
    namespace: null
    namespaceSelector: {}
    relabelings: []
    scrapeTimeout: null
  tolerations: []
ruler:
  affinity: {}
  annotations: {}
  containerSecurityContext:
    allowPrivilegeEscalation: false
    capabilities:
      drop:
      - ALL
    readOnlyRootFilesystem: true
  enabled: true
  env: []
  extraArgs: {}
  extraContainers: []
  extraEnvFrom: []
  extraVolumeMounts: []
  extraVolumes: []
  image: null
  initContainers: []
  jaegerReporterMaxQueueSize: 1000
  kedaAutoscaling:
    behavior:
      scaleDown:
        policies:
        - periodSeconds: 600
          type: Percent
          value: 10
    enabled: false
    maxReplicaCount: 10
    minReplicaCount: 1
    preserveReplicas: false
    targetCPUUtilizationPercentage: 100
    targetMemoryUtilizationPercentage: 100
  nodeSelector: {}
  persistence:
    subPath: null
  podAnnotations: {}
  podDisruptionBudget:
    maxUnavailable: 1
  podLabels: {}
  readinessProbe:
    httpGet:
      path: /ready
      port: http-metrics
    initialDelaySeconds: 45
  remoteEvaluationDedicatedQueryPath: false
  replicas: 1
  resources:
    requests:
      cpu: 100m
      memory: 128Mi
  securityContext: {}
  service:
    annotations: {}
    extraPorts: []
    internalTrafficPolicy: Cluster
    labels: {}
    type: ClusterIP
  serviceAccount:
    annotations: {}
    create: false
    labels: {}
    name: ""
  strategy:
    rollingUpdate:
      maxSurge: 50%
      maxUnavailable: 0
    type: RollingUpdate
  terminationGracePeriodSeconds: 600
  tolerations: []
  topologySpreadConstraints:
    maxSkew: 1
    topologyKey: kubernetes.io/hostname
    whenUnsatisfiable: ScheduleAnyway
ruler_querier:
  affinity: {}
  annotations: {}
  containerSecurityContext:
    allowPrivilegeEscalation: false
    capabilities:
      drop:
      - ALL
    readOnlyRootFilesystem: true
  env: []
  extraArgs: {}
  extraContainers: []
  extraEnvFrom: []
  extraVolumeMounts: []
  extraVolumes: []
  image: null
  initContainers: []
  jaegerReporterMaxQueueSize: 5000
  kedaAutoscaling:
    behavior:
      scaleDown:
        policies:
        - periodSeconds: 120
          type: Percent
          value: 10
        stabilizationWindowSeconds: 600
      scaleUp:
        policies:
        - periodSeconds: 120
          type: Percent
          value: 50
        - periodSeconds: 120
          type: Pods
          value: 15
        stabilizationWindowSeconds: 60
    enabled: false
    maxReplicaCount: 10
    minReplicaCount: 1
    preserveReplicas: false
    querySchedulerInflightRequestsThreshold: 12
  nodeSelector: {}
  persistence:
    subPath: null
  podAnnotations: {}
  podDisruptionBudget:
    maxUnavailable: 1
  podLabels: {}
  priorityClassName: null
  readinessProbe:
    httpGet:
      path: /ready
      port: http-metrics
    initialDelaySeconds: 45
  replicas: 2
  resources:
    requests:
      cpu: 100m
      memory: 128Mi
  securityContext: {}
  service:
    annotations: {}
    extraPorts: []
    internalTrafficPolicy: Cluster
    labels: {}
    type: ClusterIP
  strategy:
    rollingUpdate:
      maxSurge: 15%
      maxUnavailable: 0
    type: RollingUpdate
  terminationGracePeriodSeconds: 180
  tolerations: []
  topologySpreadConstraints:
    maxSkew: 1
    topologyKey: kubernetes.io/hostname
    whenUnsatisfiable: ScheduleAnyway
ruler_query_frontend:
  affinity: {}
  annotations: {}
  containerSecurityContext:
    allowPrivilegeEscalation: false
    capabilities:
      drop:
      - ALL
    readOnlyRootFilesystem: true
  env: []
  extraArgs: {}
  extraContainers: []
  extraEnvFrom: []
  extraVolumeMounts: []
  extraVolumes: []
  image: null
  initContainers: []
  jaegerReporterMaxQueueSize: 5000
  kedaAutoscaling:
    behavior:
      scaleDown:
        policies:
        - periodSeconds: 60
          type: Percent
          value: 10
    enabled: false
    maxReplicaCount: 10
    minReplicaCount: 1
    preserveReplicas: false
    targetCPUUtilizationPercentage: 75
    targetMemoryUtilizationPercentage: 100
  nodeSelector: {}
  persistence:
    subPath: null
  podAnnotations: {}
  podDisruptionBudget:
    maxUnavailable: 1
  podLabels: {}
  priorityClassName: null
  readinessProbe:
    httpGet:
      path: /ready
      port: http-metrics
    initialDelaySeconds: 45
  replicas: 1
  resources:
    requests:
      cpu: 100m
      memory: 128Mi
  securityContext: {}
  service:
    annotations: {}
    extraPorts: []
    internalTrafficPolicy: Cluster
    labels: {}
    type: ClusterIP
  strategy:
    rollingUpdate:
      maxSurge: 15%
      maxUnavailable: 0
    type: RollingUpdate
  terminationGracePeriodSeconds: 390
  tolerations: []
  topologySpreadConstraints:
    maxSkew: 1
    topologyKey: kubernetes.io/hostname
    whenUnsatisfiable: ScheduleAnyway
ruler_query_scheduler:
  affinity: {}
  annotations: {}
  containerSecurityContext:
    allowPrivilegeEscalation: false
    capabilities:
      drop:
      - ALL
    readOnlyRootFilesystem: true
  env: []
  extraArgs: {}
  extraContainers: []
  extraEnvFrom: []
  extraVolumeMounts: []
  extraVolumes: []
  image: null
  initContainers: []
  jaegerReporterMaxQueueSize: null
  nodeSelector: {}
  persistence:
    subPath: null
  podAnnotations: {}
  podDisruptionBudget:
    maxUnavailable: 1
  podLabels: {}
  priorityClassName: null
  readinessProbe:
    httpGet:
      path: /ready
      port: http-metrics
    initialDelaySeconds: 45
  replicas: 2
  resources:
    requests:
      cpu: 100m
      memory: 128Mi
  securityContext: {}
  service:
    annotations: {}
    extraPorts: []
    internalTrafficPolicy: Cluster
    labels: {}
    type: ClusterIP
  strategy:
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 0
    type: RollingUpdate
  terminationGracePeriodSeconds: 180
  tolerations: []
  topologySpreadConstraints:
    maxSkew: 1
    topologyKey: kubernetes.io/hostname
    whenUnsatisfiable: ScheduleAnyway
runtimeConfig: {}
serviceAccount:
  annotations: {}
  create: true
  labels: {}
  name: null
smoke_test:
  annotations: {}
  backoffLimit: 5
  env: []
  extraArgs: {}
  extraEnvFrom: []
  image: null
  initContainers: []
  priorityClassName: null
  resources: {}
  tenantId: ""
store_gateway:
  affinity:
    podAntiAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
      - labelSelector:
          matchExpressions:
          - key: target
            operator: In
            values:
            - store-gateway
        topologyKey: kubernetes.io/hostname
      - labelSelector:
          matchExpressions:
          - key: app.kubernetes.io/component
            operator: In
            values:
            - store-gateway
        topologyKey: kubernetes.io/hostname
  annotations: {}
  containerSecurityContext:
    allowPrivilegeEscalation: false
    capabilities:
      drop:
      - ALL
    readOnlyRootFilesystem: true
  enabled: true
  env: []
  extraArgs: {}
  extraContainers: []
  extraEnvFrom: []
  extraVolumeMounts: []
  extraVolumes: []
  image: null
  initContainers: []
  jaegerReporterMaxQueueSize: 1000
  nodeSelector: {}
  persistentVolume:
    accessModes:
    - ReadWriteOnce
    annotations: {}
    enableRetentionPolicy: false
    enabled: true
    name: storage
    size: 10Gi
    subPath: ""
    whenDeleted: Retain
    whenScaled: Retain
  podAnnotations: {}
  podDisruptionBudget:
    maxUnavailable: 1
  podLabels: {}
  podManagementPolicy: OrderedReady
  priorityClassName: null
  readinessProbe:
    httpGet:
      path: /ready
      port: http-metrics
    initialDelaySeconds: 60
  replicas: 3
  resources:
    limits:
      memory: 2.1Gi
    requests:
      cpu: 1
      memory: 1.5Gi
  schedulerName: ""
  securityContext: {}
  service:
    annotations: {}
    extraPorts: []
    internalTrafficPolicy: Cluster
    labels: {}
    type: ClusterIP
  strategy:
    type: RollingUpdate
  terminationGracePeriodSeconds: 120
  tolerations: []
  topologySpreadConstraints:
    maxSkew: 1
    topologyKey: kubernetes.io/hostname
    whenUnsatisfiable: ScheduleAnyway
  zoneAwareReplication:
    enabled: false
    maxUnavailable: 50
    migration:
      enabled: false
      readPath: false
    topologyKey: null
    zones:
    - extraAffinity: {}
      name: zone-a
      nodeSelector: null
      storageClass: null
    - extraAffinity: {}
      name: zone-b
      nodeSelector: null
      storageClass: null
    - extraAffinity: {}
      name: zone-c
      nodeSelector: null
      storageClass: null
tokengenJob:
  adminTokenSecret: admin-token
  annotations: {}
  containerSecurityContext:
    allowPrivilegeEscalation: false
    capabilities:
      drop:
      - ALL
    readOnlyRootFilesystem: true
  enable: true
  env: []
  extraArgs: {}
  extraEnvFrom: []
  initContainers: []
  priorityClassName: null
  securityContext: {}
  storeTokenInSecret: false
useExternalConfig: false
vaultAgent:
  caCertPath: ""
  clientCertPath: ""
  clientKeyPath: ""
  enabled: false
  roleName: ""
  serverCertPath: ""
  serverKeyPath: ""
